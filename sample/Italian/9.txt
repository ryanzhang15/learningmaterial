Differenze nell'elaborazione dei linguaggi logografici e fonologici
Poiché molte ricerche sull'elaborazione del linguaggio si sono concentrate sull'inglese e su altre lingue alfabetiche, molte teorie sull'elaborazione del linguaggio hanno sottolineato il ruolo della fonologia (ad esempio WEAVER ++) nella produzione del discorso. Linguaggi logografici contrastanti, in cui un singolo carattere è rappresentato foneticamente e ideograficamente, con linguaggi fonetici ha prodotto intuizioni su come lingue diverse si basano su diversi meccanismi di elaborazione. Gli studi sull'elaborazione dei linguaggi logografici hanno tra l'altro esaminato le differenze neurobiologiche nell'elaborazione, con un'area di particolare interesse che è la lateralizzazione emisferica. Poiché le lingue logografiche sono più strettamente associate alle immagini rispetto alle lingue alfabetiche, diversi ricercatori hanno ipotizzato che l'attivazione del lato destro dovrebbe essere più prominente nelle lingue logografiche. Sebbene alcuni studi abbiano prodotto risultati coerenti con questa ipotesi, ci sono troppi risultati contrastanti per trarre conclusioni finali sul ruolo della lateralizzazione emisferica nei linguaggi ortografici rispetto a quelli fonetici.[6].

Un altro argomento a cui è stata prestata una certa attenzione sono le differenze nel trattamento degli omofoni. Verdonschot et al.[7] esaminato le differenze nel tempo necessario per leggere un omofono ad alta voce quando un'immagine che era correlata o non correlata[8] a un personaggio omofonico veniva presentata prima del personaggio. Sono stati esaminati omofoni sia giapponesi che cinesi. Considerando che la produzione di parole di lingue alfabetiche (come l'inglese) ha mostrato un'immunità relativamente robusta agli effetti degli stimoli di contesto[9], Verdschot et al.[10] ha scoperto che gli omofoni giapponesi sembrano particolarmente sensibili a questi tipi di effetti. In particolare, i tempi di reazione erano più brevi quando ai partecipanti veniva presentata un'immagine fonologicamente correlata prima che gli fosse chiesto di leggere un personaggio bersaglio ad alta voce. Un esempio di uno stimolo fonologicamente correlato dallo studio sarebbe ad esempio quando ai partecipanti è stata presentata un'immagine di un elefante, che si pronuncia zou in giapponese, prima di essere presentata con il carattere cinese造, che si legge anche zou. Nessun effetto di immagini di contesto fonologicamente correlate è stato trovato per i tempi di reazione per la lettura di parole cinesi. Un confronto tra le lingue logografiche giapponese e cinese è interessante perché mentre la lingua giapponese è composta da oltre il 60% di eterofoni omografici (caratteri che possono essere letti in due o più modi diversi), la maggior parte dei caratteri cinesi ha una sola lettura. Poiché entrambe le lingue sono logografiche, la differenza di latenza nella lettura ad alta voce del giapponese e del cinese dovuta agli effetti del contesto non può essere attribuita alla natura logografica delle lingue. Invece, gli autori ipotizzano che la differenza nei tempi di latenza sia dovuta a costi di elaborazione aggiuntivi in giapponese, dove il lettore non può fare affidamento esclusivamente su un percorso ortografico-fonologico diretto, ma è necessario accedere anche alle informazioni a livello lessicale-sintattico per scegliere la pronuncia corretta. Questa ipotesi è confermata da studi che hanno scoperto che i giapponesi malati di Alzheimer, la cui comprensione dei caratteri si era deteriorata, potevano ancora leggere le parole ad alta voce senza particolari difficoltà[11][12].

Gli studi che contrastano l'elaborazione di omofoni inglesi e cinesi in compiti decisionali lessicali hanno trovato un vantaggio per l'elaborazione di omofoni in cinese e uno svantaggio per l'elaborazione di omofoni in inglese[13]. Lo svantaggio di elaborazione in inglese è solitamente descritto in termini di relativa mancanza di omofoni in lingua inglese. Quando si incontra una parola omofonica, viene prima attivata la rappresentazione fonologica di quella parola. Tuttavia, poiché si tratta di uno stimolo ambiguo, è necessario un abbinamento a livello ortografico/lessicale ("dizionario mentale") prima che lo stimolo possa essere disambiguato e si possa scegliere la pronuncia corretta. Al contrario, in una lingua (come il cinese) in cui esistono molti caratteri con la stessa lettura, si ipotizza che la persona che legge il personaggio avrà più familiarità con gli omofoni e che questa familiarità aiuterà l'elaborazione del carattere e il selezione successiva della pronuncia corretta, che porta a tempi di reazione più brevi durante la partecipazione allo stimolo. condotto una serie di esperimenti utilizzando il giapponese come lingua target. Durante il controllo per familiarità, hanno trovato un vantaggio di elaborazione per gli omofoni rispetto ai non omofoni in giapponese, simile a quello che è stato precedentemente trovato in cinese. I ricercatori hanno anche verificato se gli omofoni ortograficamente simili avrebbero prodotto uno svantaggio nell'elaborazione, come è avvenuto con gli omofoni inglesi[14], ma non ha trovato prove per questo. È evidente che c'è una differenza nel modo in cui gli omofoni vengono elaborati nelle lingue logografiche e alfabetiche, ma se il vantaggio per l'elaborazione degli omofoni nelle lingue logografiche giapponese e cinese è dovuto alla natura logografica degli carattere, o se riflette semplicemente un resta da vedere il vantaggio per le lingue con più omofoni indipendentemente dalla natura della scrittura.